#
# tags, image-source, nfs mounts all have dashes
# labels do not
# Nothing else should have dashes
# 

holder-cluster:
  controller:
    hostname: holder-cluster-controller
    project: holder-dd34a9
    image-source:
      - https://compute.googleapis.com/compute/v1/projects/holder-dd34a9/global/images/holder-cluster-compute-image
    minion-id: holder.pennbrain.upenn.edu
    tags:
      - controller
      - holder
    labels:
      billing-project: holder-dd34a9
    nfs:
      - /apps
      - /home
      - /etc/munge
    machine-type: n1-standard-2
    boot-disk-size: 10G
    zone: us-east1-b
    region: us-east1
    service-account: slurm-gcp@holder-dd34a9.iam.gserviceaccount.com
    ExternalIP: 35.231.194.165
    network: bsc-host-network
    Subnet: holder-dd3499-subnet
    SharedVPCHostProj: pennbrain-host-3097383fff
    VPCSubnet: holder-subnet
    NetworkType: subnetwork
    UpdateNodeAddresses: True

    
  partitions:
    default:
        nodes:
            name: DEFAULT
            ImageProject: holder-dd34a9
            Family: holder-cluster-compute-image
            ExternalIP: False
            Region: us-east1
            Zone: us-east1-b
            Preemptible: True
            DiskSizeGB: 10
            DiskType: pd-standard
            MachineType: n1-standard-2
            Labels:
              key1: value1
              key2: value2
            Tags:
              - tag1
              - tag2
            GPUType: 
            GPUCount: 0

    debug:
        project: holder-dd34a9
        Default: True
        nodes:
            name: holder-cluster-compute[0-2]
            image-source:
              - https://compute.googleapis.com/compute/v1/projects/holder-dd34a9/global/images/holder-cluster-compute-image
              - https://compute.googleapis.com/compute/v1/projects/ubuntu-os-cloud/global/images/ubuntu-1910
            DiskSizeGB: 10
            DiskType: pd-standard
            MachineType: n1-standard-1
            Preemptible: True
            NetworkPath: projects/pennbrain-host-3097383fff/global/networks/bsc-host-network
            Tags:
              - compute
              - holder
            Labels:
              billing-project: holder-dd34a9
              secondlabel: labelvalue

    proj-a-n1-standard-2:
        project: holder-proj-a
        nodes:
            name: proj-a-n1-standard-2-[00-02]
            DiskSizeGB: 10
            DiskType: pd-standard
            MachineType: n1-standard-2
            NetworkPath: projects/pennbrain-host-3097383fff/global/networks/bsc-host-network
            Preemptible: True
            Tags:
              - compute
              - holder
            Labels:
              billing-project: holder-proj-a
              secondlabel: labelvalue
    
    big-proj-a:
        nodes: 
          name: n1-highmem-16-[00-09]
          MachineType: n1-highmem-16
          tags:
            - compute
            - holder
          preemptible: False
        project: holder-proj-a
        labels:
          billing-project: holder-proj-a
    
    gpu-proj-a:
        nodes: 
          name: gpu-[00-09]
          MachineType: n1-standard-4
          Gres: gpu:p102:1
          tags:
            - compute
            - holder
          preemptible: True
        project: holder-proj-a
        labels:
          billing-project: holder-proj-a

#
# Probably want to use TmpDisk to specify a tmp disk to add to the system
# AllowGroups
# Can we change Sockets/CoresPerSocket/ThreadsPerCore to just CPU?
#
#NodeName=DEFAULT MaxTime=INFINITE State=CLOUD LLN=yes 
#
#GresTypes=gpu
#
#NodeName=proja-small-queue-n1-standard-2-[0-99] Sockets=1 CoresPerSocket=1 ThreadsPerCore=2 RealMemory=7070 State=CLOUD
#
#PartitionName=proja-small-queue Nodes=proja-small-queue-n1-standard-2-[0-99] Default=NO MaxTime=INFINITE State=UP DefMemPerCPU=3535 LLN=yes
#
#NodeName=proja-big-queue-n1-highmem-32-[0-9] Sockets=1 CoresPerSocket=16 ThreadsPerCore=2 RealMemory=206352 State=CLOUD
#
#PartitionName=proja-big-queue Nodes=proja-big-queue-n1-highmem-32-[0-9] Default=NO MaxTime=INFINITE State=UP DefMemPerCPU=6448 LLN=yes
#
#NodeName=garcea-queue-n1-highmem-32-[0-49] Sockets=1 CoresPerSocket=16 ThreadsPerCore=2 RealMemory=206352 State=CLOUD
#
#PartitionName=garcea-queue Nodes=garcea-queue-n1-highmem-32-[0-49] Default=NO MaxTime=INFINITE State=UP DefMemPerCPU=6448 LLN=yes
#
#NodeName=proja-gpu-queue-n1-standard-4-[0-9] Sockets=1 CoresPerSocket=2 ThreadsPerCore=2 RealMemory=14510 State=CLOUD Gres=gpu:p100:1
#
#PartitionName=proja-gpu-queue Nodes=proja-gpu-queue-n1-standard-4-[0-9] Default=NO MaxTime=INFINITE State=UP DefMemPerCPU=6448 LLN=yes
#
#NodeName=projb-small-queue-n1-standard-2-[0-99] Sockets=1 CoresPerSocket=1 ThreadsPerCore=2 RealMemory=7070 State=CLOUD
#
#PartitionName=projb-small-queue Nodes=projb-small-queue-n1-standard-2-[0-99] Default=NO MaxTime=INFINITE State=UP DefMemPerCPU=6448 LLN=yes
